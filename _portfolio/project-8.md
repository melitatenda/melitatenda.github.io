---
title: "People's privacy concerns about new technology (focusing on LLMs)"
# excerpt: "Designing a framework to transfer skilled motions from casually captured videos of humans and animals to legged robots, including quadrupeds and humanoids, to eliminate the need for expensive motion capture systems and expert animators."
collection: portfolio
---

This study explored how people perceive and respond to privacy risks when using Large Language Models (LLMs). Through a survey of 25 participants, the research examined usersâ€™ knowledge levels, risk perceptions, and behavioral adaptations toward LLM privacy. The findings revealed a significant gap between perceived and actual privacy risks, with users who had lower privacy knowledge expressing higher concern levels.

Results showed that 70% of participants adjusted their LLM usage due to privacy worries, often by limiting personal data sharing or avoiding sensitive topics. Knowledgeable users demonstrated more nuanced behavior, balancing functionality with caution, while younger participants tended to prioritize convenience over privacy. These insights highlight the complexity of user behavior and the influence of demographic and knowledge factors on privacy decisions.

The study emphasizes the need for user education, transparent privacy practices, and privacy-by-design principles in LLM development. It recommends tailored awareness campaigns, stronger data protection mechanisms, and inclusive regulatory frameworks to better safeguard users. Future research should involve larger, more diverse populations and focus on long-term changes in privacy perceptions as LLMs become more integrated into daily life.
